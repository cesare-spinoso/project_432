{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be looking at ways to use linear models to predict electricity demand for the GTA. We will trying different combinations of features through best subset selection which in the end should give us a sense of the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 't' which is just the index of each date starting at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the seasonality in the data it will not be enough to consider a linear model of the form $X_t = \\beta_1 t + \\beta_0$ as this would only pickup on the underlying linear trend in the data (for which we already suspect is relatively weak according to our intial plots and time series decomposition <b>Note to self: this may be subject to change depending on how the time series analysis goes</b>).\n",
    "\n",
    "We need to introduce some seasonal behaviour in our linear model. One way to do this (<b>CITE HERE</b>) is through fourier feature bases. If $m$ is the seasonal period we suspect (e.g. daily, weekly, monthly, yearly) then we can introduce terms of the following form:\n",
    "$X_t = \\sum_{j=1}^P \\beta_{2j-1} \\sin(\\frac{2 \\pi j t}{m}) + \\beta_{2j} \\cos(\\frac{2 \\pi j t}{m})$\n",
    "where $m$ is the the seasonal period and $P$ is the number of pairs of fourier series we have. We will bound $P$ to at most $\\frac{m}{2}$. For daily seasonality $m=24$, for weekly $m=7 \\times 24$, for monthly $m = 4 \\times 7 \\times 24$ (using the running assumption that we use a month as 4 weeks) and yearly as $365 \\times 24 = 8760$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for each of the fourier bases from j = 1 to P and for each different seasonality\n",
    "# for j = 1 to m/2, but do this in ranges:\n",
    "# for m = 24 use the range [1,...12]\n",
    "# For m = 7*24 use a longer range like [1, 6, 12, ..., P] (so we don't blow up training)\n",
    "# For m = 4*7*42 use a longer range [1, 12, ... P] (remember P = m/2 use P - 1 to be safe actually)\n",
    "# Again the same thing for m = 8760 use a larger ranger something divisible by 8760 like 10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each possible pair train the model with cross validation with the following function\n",
    "#The model is the sklearn model, the n_splits is the number of folds (try to find a reasonable\n",
    "# size but i suspect we won't be able to do it a large number of splits, there's just\n",
    "# too much data! )\n",
    "# X is the transformed set of features and y is the target electricity demand\n",
    "def rolling_window_time_series(model, n_splits, X, y):\n",
    "    # Keep a running total of the mean mse\n",
    "    mse_cv = 0\n",
    "    N = 1\n",
    "    ts_splitter = sklearn.model_selection.TimeSeriesSplit(n_splits=n_splits)\n",
    "    for train, valid in ts_splitter.split(X):\n",
    "        # For each train, valid fold fit it on train\n",
    "        model.fit(X[train], y[train])\n",
    "        # Predict on valid\n",
    "        y_pred = model.predict(X[valid])\n",
    "        # Find mse of this fold and then add it to the running average\n",
    "        mse_fold = sklearn.metrics.mean_squared_error(y_true=y[valid], y_pred=y_pred)\n",
    "        # This is to keep a running average (instead of appending to an array and then\n",
    "        # taking the mean)\n",
    "        if N == 1:\n",
    "            mse_cv = mse_fold\n",
    "        else:\n",
    "            # This can be checked by expanding the formula for the mean\n",
    "            mse_cv += (mse_fold - mse_cv)/N\n",
    "        N+=1\n",
    "    # Return mse and rmse\n",
    "    return mse_cv, math.sqrt(mse_cv)\n",
    "\n",
    "# 1. So high level it's like a for loop over all possible combiantions of parameters\n",
    "# 2. For each of those combinations train the model using cross validation\n",
    "# Record the average mse => 2. should be done by the function rolling_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you get the optimal fourier series linear_model\n",
    "# Do best subset selection on the 10 features so 2^10 combinations now added to the \n",
    "# best model you found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}